{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"e2020 Browser App Field Manual This document describes the e2020 browser app for the purposes of: integration with other site components; servicing; maintenance; enhancement. Use the sidebar to navigate to a relevant section. Description documents present an overview of the app, outside of the context of any particular task. Architecture Decision Records are records of major or surprising architectural decisions. They are maintained so that the reasons are not lost during later review or auditing. Standards describe the target standards for our app.","title":"Home"},{"location":"#e2020-browser-app-field-manual","text":"This document describes the e2020 browser app for the purposes of: integration with other site components; servicing; maintenance; enhancement. Use the sidebar to navigate to a relevant section. Description documents present an overview of the app, outside of the context of any particular task. Architecture Decision Records are records of major or surprising architectural decisions. They are maintained so that the reasons are not lost during later review or auditing. Standards describe the target standards for our app.","title":"e2020 Browser App Field Manual"},{"location":"desc-build/","text":"","title":"Build System"},{"location":"desc-components/","text":"Major Components Mainloop and Scheduling As much as possible runs out of a mainloop driven by requestanimationframe events (hereafter \"raf events\"). A dedicated scheduler attempts to ensure that the raf hanlder returns in plenty of time. Jank Detection Visual smoothness benefits from regular updates of visual content even if that is less than the maximum available rate. Variable update rates tend to be noticable even if correctly timed. To this end draw events are scheduled at 20Hz, 30Hz, or 60Hz and no intermediate speed. Raf events which correspond to this (parhaps reduced rate) are called on-beats. In an on-beat drawing gets the top scheduler priority. The other events, off-beats, do not include the drawing callbacks. A jank detector updates the optimal rate for the hardware based on a record of performance of earlier events. Each raf is tested to see if it has burst , that is met or exceeded its allocated time. This is a simple boolean. The record and timing of far bursts is the input to the jank detector. The output is the rate of on-requests, known as the \"gear\" or \"timesig\". This behaviour and fix is the result of observed behaviour, not conjecture, and follows various ineffective \"simpler\" fixes. Jank Detection Algorithm It has not proved possible to reliably tell which gear minimises raf bursts except by applying gears and seeing what happens. The jank-detection algorithm takes the raf burst flag and the current time and sets the gear. As experimentation is required and it amounts to a \"bang-bang\" controller (ie non-proportional) the best behaviour we can expect to observe is slow \"hunting\" between an under- and over-performant state (ie a slow oscillation). The opposite behaviour to \"hunting\" here is \"moving\" which is a conserted movement through gears in one direction or another. The jank-detection algorithm considers to successive changes in the same direction to be moving, two in opposite directions to be hunting. If the period between changes during \"hunting\" is too long we will never take advantage of performance changes (such as recovery after one-off events). If too short, the rate becomes unstable and jank is observed. If a burst occurs, the rate is decreased immediately. Following this event, a grace period ensures that no opposing rate increase occurs for a fixed (wall-clock) time to avoid excessively-quick hunting on a stable, quiescent system. Once the grace period expires, the rate is increased again to allow potential recovery. The grace period increases exponentially (fibbionacci, to a fixed limit) all the while the rate is hunting, as long as a hunt occured during the grace period (indicating that the higher rate is not stable). It decreases by the same exponential curve if the hunting period is longer than expected (indicating a system stable at the faster rate). This ensures that the rate \"settles\" on a stable system. When moving is detected the rate is reset to allow fast accommodation of changes. Scheduling algorithm The scheduler accepts callbacks which are placed in an on-beat or off-beat queues, as requested by the caller, and of a certain priority. This priority should be a small, positive integer. The list of on-beat queues and the list of off-beat queues (each a queuelist ) are combined to form the scheduler. For an on-beat, the on queuelist is run, followed by the off queuelist. For an off-beat only the off queuelist is run. An off-beat raf is considered to have burst if the off-beat queuelist bursts as it is the only queuelist run in an off-beat. An on-beat raf is only considered to have burst if the on-beat queuelist bursts as this is all that's \"expected\" to run on an on-beat. The exception is when running in gear one, ie 60Hz. In this case either queuelist bursting counts as a burst as there are no other opportunities to run off-beat tasks. Within a queuelist are queues. Queues are arranged in order of priority. Each queue is run from lowest priority to highest in round-robin. Note that low-priority queues never get run if high-priorirty queues consume all the time, so be cautious with fine-graining priorities. At present queues are stored in a vec so please keep priorities ultra-compact. Code Structure controller/scheduler -- the scheduler schedgroup.rs -- a group of tasks (which are dropped when the group is) schedmain.rs -- main implementation of scheduler \"tick\" schedqueue.rs -- a queue type in the algorithm above schedqueuelist.rs -- the queuelist type in the algorithm above schedrun.rs -- an object passed to the callback to help control the scheduler schedtask.rs -- the internal datatype used to represent the callback scheduler.rs -- main entry point to the scheduler Instrumentation Each queue run and task are integrated with the blackbox via the scheduler-* event stream which capture stream performance. The scheduler and scheduler-jank streams provide further logging. Tasks The following tasks are currently implemented: scheduler-task-http-manager -- issuing http requests scheduler-task-xfer -- http data repsonses scheduler-task-t\u00e1code -- t\u00e1naiste interpreter scheduler-task-blackbox -- blackbox callback scheduler-task-resizer -- canvas resize detection scheduler-task-report -- state-reporting javascript events scheduler-task-viewport-report -- position-reporting javascript events scheduler-task-physics -- mouse movement (left/right) scheduler-task-optical -- mouse movement (in/out) scheduler-task-compositor -- converting shapes into WebGL primitives scheduler-task-draw -- drawing (on-beat) Except for scheduler-task-draw all others are off-beat tasks. Instrumentation Instrumentation code exists to assist development and debugging of the browser app. It is generally not available in deployed builds to reduce file size and improve performance. Black Box The black box system periodically sends logs and data sets to the backend server. There, the server stores this data in filesi, according to server configuration. The backend server also controls which datasets and logs are captured, and the frequency of callbacks. These are controlled by a configuration file. This file is sent to the client as the response to each request containing data. The primary use of the black box is to monitor performance. Data sets are arranged into streams which are represented by a string. Each log or data capture includes the stream to which it belongs. The server configures which logs and data to capture and their destination file based on the originating stream. A stack allows a log message to be contextualised by pusing and popping string context as to its location. This allows the same log messages to be divided into subsets. The stack mechanism is relatively heavyweight and designed only for debugging rather than long-lived instrumentation. The blackbox supports abstract drivers. These use different mechanisms to report to the server. Currently only an http driver and null driver are implemented. Important Files app/data/blackbox -- contains rust files implementing the blackbox: core blackbox.rs -- high-level static API for use in macros. blackboxstate.rs -- current state of blackbox on client. bbreportstream.rs -- implements a single stream's pending contents. drivers blackboxdriver.rs -- facade around driver implementations. httpblackboxdriver.rs -- driver implementation for HTTP callbacks. nullblackboxdriver.rs -- no-op driver implementation. stubdriver.rs -- non-implementation of driver for production builds macros.rs -- macros to use blackbox in code. debug_mode.yaml -- server side configuration POST /browser/debug -- API endpoint Macros The blackbox is used exclusively through macros. bb_time(stream,block) -- execute block, timing it and adding to stream dataset. bb_metronome(stream) -- add to dataset interval between each call to this macro for this stream bb_log(stream,format,args) -- write formatted log message to stream bb_stack(string,block) -- push \"string\" onto stack and execute block Payload Format (POST /browser/debug) Client to Server Payload POST request with raw JSON payload. { \"instance_id\": \"<string>\", /* browser-identifying string */ \"streams\": { \"<stream-name>\": { \"reports\": [ { \"time\": <number>, /* ms since unix epoch */ \"text\": \"<string>\", /* log contents */ \"stack\": \"<string>\" /* stack at time of logging */ },... ], \"dataset\": [<number>,...] /* dataset. Key may be absent if not configured */ } }, ... } } Server to Client POST request response with raw JSON payload. The whole contents of debug_mode.yaml are sent (ranscoded), though the server only reacts to some keys. { \"enabled\": [\"<string>\",...], /* streams to enable */ \"dataset\": [\"<string>\",...], /* datasets to enable (stream must also be enabled) */ \"interval\": <number>, /* requested interval (in seconds) between updates */ }","title":"Major Components"},{"location":"desc-components/#major-components","text":"","title":"Major Components"},{"location":"desc-components/#mainloop-and-scheduling","text":"As much as possible runs out of a mainloop driven by requestanimationframe events (hereafter \"raf events\"). A dedicated scheduler attempts to ensure that the raf hanlder returns in plenty of time.","title":"Mainloop and Scheduling"},{"location":"desc-components/#jank-detection","text":"Visual smoothness benefits from regular updates of visual content even if that is less than the maximum available rate. Variable update rates tend to be noticable even if correctly timed. To this end draw events are scheduled at 20Hz, 30Hz, or 60Hz and no intermediate speed. Raf events which correspond to this (parhaps reduced rate) are called on-beats. In an on-beat drawing gets the top scheduler priority. The other events, off-beats, do not include the drawing callbacks. A jank detector updates the optimal rate for the hardware based on a record of performance of earlier events. Each raf is tested to see if it has burst , that is met or exceeded its allocated time. This is a simple boolean. The record and timing of far bursts is the input to the jank detector. The output is the rate of on-requests, known as the \"gear\" or \"timesig\". This behaviour and fix is the result of observed behaviour, not conjecture, and follows various ineffective \"simpler\" fixes.","title":"Jank Detection"},{"location":"desc-components/#jank-detection-algorithm","text":"It has not proved possible to reliably tell which gear minimises raf bursts except by applying gears and seeing what happens. The jank-detection algorithm takes the raf burst flag and the current time and sets the gear. As experimentation is required and it amounts to a \"bang-bang\" controller (ie non-proportional) the best behaviour we can expect to observe is slow \"hunting\" between an under- and over-performant state (ie a slow oscillation). The opposite behaviour to \"hunting\" here is \"moving\" which is a conserted movement through gears in one direction or another. The jank-detection algorithm considers to successive changes in the same direction to be moving, two in opposite directions to be hunting. If the period between changes during \"hunting\" is too long we will never take advantage of performance changes (such as recovery after one-off events). If too short, the rate becomes unstable and jank is observed. If a burst occurs, the rate is decreased immediately. Following this event, a grace period ensures that no opposing rate increase occurs for a fixed (wall-clock) time to avoid excessively-quick hunting on a stable, quiescent system. Once the grace period expires, the rate is increased again to allow potential recovery. The grace period increases exponentially (fibbionacci, to a fixed limit) all the while the rate is hunting, as long as a hunt occured during the grace period (indicating that the higher rate is not stable). It decreases by the same exponential curve if the hunting period is longer than expected (indicating a system stable at the faster rate). This ensures that the rate \"settles\" on a stable system. When moving is detected the rate is reset to allow fast accommodation of changes.","title":"Jank Detection Algorithm"},{"location":"desc-components/#scheduling-algorithm","text":"The scheduler accepts callbacks which are placed in an on-beat or off-beat queues, as requested by the caller, and of a certain priority. This priority should be a small, positive integer. The list of on-beat queues and the list of off-beat queues (each a queuelist ) are combined to form the scheduler. For an on-beat, the on queuelist is run, followed by the off queuelist. For an off-beat only the off queuelist is run. An off-beat raf is considered to have burst if the off-beat queuelist bursts as it is the only queuelist run in an off-beat. An on-beat raf is only considered to have burst if the on-beat queuelist bursts as this is all that's \"expected\" to run on an on-beat. The exception is when running in gear one, ie 60Hz. In this case either queuelist bursting counts as a burst as there are no other opportunities to run off-beat tasks. Within a queuelist are queues. Queues are arranged in order of priority. Each queue is run from lowest priority to highest in round-robin. Note that low-priority queues never get run if high-priorirty queues consume all the time, so be cautious with fine-graining priorities. At present queues are stored in a vec so please keep priorities ultra-compact.","title":"Scheduling algorithm"},{"location":"desc-components/#code-structure","text":"controller/scheduler -- the scheduler schedgroup.rs -- a group of tasks (which are dropped when the group is) schedmain.rs -- main implementation of scheduler \"tick\" schedqueue.rs -- a queue type in the algorithm above schedqueuelist.rs -- the queuelist type in the algorithm above schedrun.rs -- an object passed to the callback to help control the scheduler schedtask.rs -- the internal datatype used to represent the callback scheduler.rs -- main entry point to the scheduler","title":"Code Structure"},{"location":"desc-components/#instrumentation","text":"Each queue run and task are integrated with the blackbox via the scheduler-* event stream which capture stream performance. The scheduler and scheduler-jank streams provide further logging.","title":"Instrumentation"},{"location":"desc-components/#tasks","text":"The following tasks are currently implemented: scheduler-task-http-manager -- issuing http requests scheduler-task-xfer -- http data repsonses scheduler-task-t\u00e1code -- t\u00e1naiste interpreter scheduler-task-blackbox -- blackbox callback scheduler-task-resizer -- canvas resize detection scheduler-task-report -- state-reporting javascript events scheduler-task-viewport-report -- position-reporting javascript events scheduler-task-physics -- mouse movement (left/right) scheduler-task-optical -- mouse movement (in/out) scheduler-task-compositor -- converting shapes into WebGL primitives scheduler-task-draw -- drawing (on-beat) Except for scheduler-task-draw all others are off-beat tasks.","title":"Tasks"},{"location":"desc-components/#instrumentation_1","text":"Instrumentation code exists to assist development and debugging of the browser app. It is generally not available in deployed builds to reduce file size and improve performance.","title":"Instrumentation"},{"location":"desc-components/#black-box","text":"The black box system periodically sends logs and data sets to the backend server. There, the server stores this data in filesi, according to server configuration. The backend server also controls which datasets and logs are captured, and the frequency of callbacks. These are controlled by a configuration file. This file is sent to the client as the response to each request containing data. The primary use of the black box is to monitor performance. Data sets are arranged into streams which are represented by a string. Each log or data capture includes the stream to which it belongs. The server configures which logs and data to capture and their destination file based on the originating stream. A stack allows a log message to be contextualised by pusing and popping string context as to its location. This allows the same log messages to be divided into subsets. The stack mechanism is relatively heavyweight and designed only for debugging rather than long-lived instrumentation. The blackbox supports abstract drivers. These use different mechanisms to report to the server. Currently only an http driver and null driver are implemented.","title":"Black Box"},{"location":"desc-components/#important-files","text":"app/data/blackbox -- contains rust files implementing the blackbox: core blackbox.rs -- high-level static API for use in macros. blackboxstate.rs -- current state of blackbox on client. bbreportstream.rs -- implements a single stream's pending contents. drivers blackboxdriver.rs -- facade around driver implementations. httpblackboxdriver.rs -- driver implementation for HTTP callbacks. nullblackboxdriver.rs -- no-op driver implementation. stubdriver.rs -- non-implementation of driver for production builds macros.rs -- macros to use blackbox in code. debug_mode.yaml -- server side configuration POST /browser/debug -- API endpoint","title":"Important Files"},{"location":"desc-components/#macros","text":"The blackbox is used exclusively through macros. bb_time(stream,block) -- execute block, timing it and adding to stream dataset. bb_metronome(stream) -- add to dataset interval between each call to this macro for this stream bb_log(stream,format,args) -- write formatted log message to stream bb_stack(string,block) -- push \"string\" onto stack and execute block","title":"Macros"},{"location":"desc-components/#payload-format-post-browserdebug","text":"","title":"Payload Format (POST /browser/debug)"},{"location":"desc-components/#client-to-server-payload","text":"POST request with raw JSON payload. { \"instance_id\": \"<string>\", /* browser-identifying string */ \"streams\": { \"<stream-name>\": { \"reports\": [ { \"time\": <number>, /* ms since unix epoch */ \"text\": \"<string>\", /* log contents */ \"stack\": \"<string>\" /* stack at time of logging */ },... ], \"dataset\": [<number>,...] /* dataset. Key may be absent if not configured */ } }, ... } }","title":"Client to Server Payload"},{"location":"desc-components/#server-to-client","text":"POST request response with raw JSON payload. The whole contents of debug_mode.yaml are sent (ranscoded), though the server only reacts to some keys. { \"enabled\": [\"<string>\",...], /* streams to enable */ \"dataset\": [\"<string>\",...], /* datasets to enable (stream must also be enabled) */ \"interval\": <number>, /* requested interval (in seconds) between updates */ }","title":"Server to Client"},{"location":"desc-integration/","text":"","title":"Integration"},{"location":"desc-source/","text":"","title":"Source Code Structure"},{"location":"standard-rust/","text":"","title":"Rust Coding Standards"},{"location":"arch/0001-webgl/","text":"0001. Use WebGL1 for browser window Date: <2018-08-31 Status Provisional Consequence of User input Context We repeatedly hear that a reason for choosing browsers other than ours is the slow and painful navigation and interaction in the browser window. This is something that has proved impossible to remedy with fixes. So we should address this issue early in the redesign. We were three technology options for the bottom layer. 2D Canvas SVG WebGL Canvas SVG and WebGL are object-based, which allows speedy rich interactions. WebGL has a clean mapping to the browser's graphics card, making it closer \"to the metal\", which makes it easier to keep it efficient as the number of objects scale. The ability to use custom shaders in WebGL allows common operations to be entirely GPU-based, saving CPU for other screen components. 2D canvas has the simplest API, SVG next. The WebGL API is ver difficult to use. Browsers do not yet support WebGL2 reliably, so WebGL1 is chosen. However, the two technologies are similar and it should be possible to migrate without disruption (if forced into it). Decision Use WebGL1. Consequences We need a wrapper around the WebGL1 API to hide WebGL complexities.","title":"0001 Use WebGL"},{"location":"arch/0001-webgl/#0001-use-webgl1-for-browser-window","text":"Date: <2018-08-31","title":"0001. Use WebGL1 for browser window"},{"location":"arch/0001-webgl/#status","text":"Provisional","title":"Status"},{"location":"arch/0001-webgl/#consequence-of","text":"User input","title":"Consequence of"},{"location":"arch/0001-webgl/#context","text":"We repeatedly hear that a reason for choosing browsers other than ours is the slow and painful navigation and interaction in the browser window. This is something that has proved impossible to remedy with fixes. So we should address this issue early in the redesign. We were three technology options for the bottom layer. 2D Canvas SVG WebGL Canvas SVG and WebGL are object-based, which allows speedy rich interactions. WebGL has a clean mapping to the browser's graphics card, making it closer \"to the metal\", which makes it easier to keep it efficient as the number of objects scale. The ability to use custom shaders in WebGL allows common operations to be entirely GPU-based, saving CPU for other screen components. 2D canvas has the simplest API, SVG next. The WebGL API is ver difficult to use. Browsers do not yet support WebGL2 reliably, so WebGL1 is chosen. However, the two technologies are similar and it should be possible to migrate without disruption (if forced into it).","title":"Context"},{"location":"arch/0001-webgl/#decision","text":"Use WebGL1.","title":"Decision"},{"location":"arch/0001-webgl/#consequences","text":"We need a wrapper around the WebGL1 API to hide WebGL complexities.","title":"Consequences"},{"location":"arch/0002-wrap-webgl/","text":"0002. Wrap WebGL in browser-specific API. Date: <2018-08-31 Status Provisional Consequence of ADR-0001 Context Following ADR-0001 to use WebGL1, the high complexity of the WebGL API needs shielding from other parts of the code to: make our code more maintainable, to hide some WebGL housekeeping, allow other backends, eg for export, or ancient browsers. This layer needs to be implemented for efficient manipulation of large data sets while keeping the screen responsive as a key requirement for the browser window is responsiveness (see ADR-0001) and it will be throwing around large amounts of data. Decision Implement WebGL wrapper layer. Consequences All interaction with the screen is through an API of our own which closely represents the interactions of a browser window. It must be implemented in an efficient manner from the perspective of large dataset manipulation.","title":"0002 Wrap WebGL"},{"location":"arch/0002-wrap-webgl/#0002-wrap-webgl-in-browser-specific-api","text":"Date: <2018-08-31","title":"0002. Wrap WebGL in browser-specific API."},{"location":"arch/0002-wrap-webgl/#status","text":"Provisional","title":"Status"},{"location":"arch/0002-wrap-webgl/#consequence-of","text":"ADR-0001","title":"Consequence of"},{"location":"arch/0002-wrap-webgl/#context","text":"Following ADR-0001 to use WebGL1, the high complexity of the WebGL API needs shielding from other parts of the code to: make our code more maintainable, to hide some WebGL housekeeping, allow other backends, eg for export, or ancient browsers. This layer needs to be implemented for efficient manipulation of large data sets while keeping the screen responsive as a key requirement for the browser window is responsiveness (see ADR-0001) and it will be throwing around large amounts of data.","title":"Context"},{"location":"arch/0002-wrap-webgl/#decision","text":"Implement WebGL wrapper layer.","title":"Decision"},{"location":"arch/0002-wrap-webgl/#consequences","text":"All interaction with the screen is through an API of our own which closely represents the interactions of a browser window. It must be implemented in an efficient manner from the perspective of large dataset manipulation.","title":"Consequences"},{"location":"arch/0003-use-wasm/","text":"0003. Use Web-Assembly (WASM) for WebGL Wrapper Date: <2018-08-31 Status Provisional Consequence of ADR-0002 Context ADR-0002 (to wrap WebGL) identified the need for a good place in-browser for doing data heavy-lifting. Data manipulation in GC-ed environments tends to suffer easily from jank when there are realtime refresh constraints. Single-threaded environments (such as the basic model for in-browser js) are particularly sueecptible. Browsers offer a number of alternatives to this status quo which take code out of the event processing loop. These include asm.js WebWorkers Web Assembly Any of these would have helped. But only the latter offers a GC-cycle-free environment. Staying inside the JS domain (such as with web-workers) would also mean needing great care to avoid unnecessary copies, handle boxing efficiently, GC, etc, due to the JS memory model. Decision Use WASM for efficient data munging. Consequences We need to fine a sane language which can target WASM.","title":"0003 Use WASM"},{"location":"arch/0003-use-wasm/#0003-use-web-assembly-wasm-for-webgl-wrapper","text":"Date: <2018-08-31","title":"0003. Use Web-Assembly (WASM) for WebGL Wrapper"},{"location":"arch/0003-use-wasm/#status","text":"Provisional","title":"Status"},{"location":"arch/0003-use-wasm/#consequence-of","text":"ADR-0002","title":"Consequence of"},{"location":"arch/0003-use-wasm/#context","text":"ADR-0002 (to wrap WebGL) identified the need for a good place in-browser for doing data heavy-lifting. Data manipulation in GC-ed environments tends to suffer easily from jank when there are realtime refresh constraints. Single-threaded environments (such as the basic model for in-browser js) are particularly sueecptible. Browsers offer a number of alternatives to this status quo which take code out of the event processing loop. These include asm.js WebWorkers Web Assembly Any of these would have helped. But only the latter offers a GC-cycle-free environment. Staying inside the JS domain (such as with web-workers) would also mean needing great care to avoid unnecessary copies, handle boxing efficiently, GC, etc, due to the JS memory model.","title":"Context"},{"location":"arch/0003-use-wasm/#decision","text":"Use WASM for efficient data munging.","title":"Decision"},{"location":"arch/0003-use-wasm/#consequences","text":"We need to fine a sane language which can target WASM.","title":"Consequences"},{"location":"arch/0004-use-rust/","text":"0004. Use Rust Date: <2018-08-31 Status Provisional Consequence of ADR-0003 Context WASM, the design choice of ADR-0003, is a compiled language which needs a source. Languages targeting WASM (typically via LLVM) tend to be at the other end of the language spectrum to JS, being compiled, statically-typed and with largely manual memory management. After a survey of the available languages Rust seemed to be the least offensive for the writing of a web application. It includes libraries which interface well with browser APIs and is generally \"safe\". Rust has reasonable, if not spectacular adoption, including in the web community. If the language or libraries flounder, the migration path to JS would be tedious but not complex or insurmountable, being largely one-to-one. In that case we will have benefitted from the safeness of rust in the design phase. Decision Use Rust to target WASM. Consequences We need to choose libraries and tooling.","title":"0004 Use Rust"},{"location":"arch/0004-use-rust/#0004-use-rust","text":"Date: <2018-08-31","title":"0004. Use Rust"},{"location":"arch/0004-use-rust/#status","text":"Provisional","title":"Status"},{"location":"arch/0004-use-rust/#consequence-of","text":"ADR-0003","title":"Consequence of"},{"location":"arch/0004-use-rust/#context","text":"WASM, the design choice of ADR-0003, is a compiled language which needs a source. Languages targeting WASM (typically via LLVM) tend to be at the other end of the language spectrum to JS, being compiled, statically-typed and with largely manual memory management. After a survey of the available languages Rust seemed to be the least offensive for the writing of a web application. It includes libraries which interface well with browser APIs and is generally \"safe\". Rust has reasonable, if not spectacular adoption, including in the web community. If the language or libraries flounder, the migration path to JS would be tedious but not complex or insurmountable, being largely one-to-one. In that case we will have benefitted from the safeness of rust in the design phase.","title":"Context"},{"location":"arch/0004-use-rust/#decision","text":"Use Rust to target WASM.","title":"Decision"},{"location":"arch/0004-use-rust/#consequences","text":"We need to choose libraries and tooling.","title":"Consequences"},{"location":"arch/0005-breakpoints/","text":"0005. Breakpoints at 1000..., 3000... Date: 2018-11 Status Provisional Consequence of None Context We need to have fixed breakpoint scales at which we can change the rendering. These should be \"round\" numbers so that we can replace without annoying rounding errors from fractional bases causing jitter. It makes sense to do it at the decade points, 1, 10, 100, etc. The current website also has breakpoints at intermediate values suggesting a need for greater definition. Scaling multiplies meaning that breakpoints need to be logarithmically distributed to be \"even\". For exmaple, if we were to have breaks at 100... and 500... this would be poor as there would be a jump of 5x followed by one of 2x between the scale points. The square root of ten is close to three, meaning choosing 100... and 300... gives jumps of 3x and 3 1/3x which is about 10% error, which is small, and provides round numbers for scales. Having more jump points would mean needing 2x jumps which interact badly with 10: 2x 2x 2x 2.625x. We can't have fewer intermediate jumps than the single one provided by 100..., 300..., so this is the best option. Decision Break points at 100... and 300... Consequences We need to choose the best scales for style changes at one of these points.","title":"0005 Scale breakpoints"},{"location":"arch/0005-breakpoints/#0005-breakpoints-at-1000-3000","text":"Date: 2018-11","title":"0005. Breakpoints at 1000..., 3000..."},{"location":"arch/0005-breakpoints/#status","text":"Provisional","title":"Status"},{"location":"arch/0005-breakpoints/#consequence-of","text":"None","title":"Consequence of"},{"location":"arch/0005-breakpoints/#context","text":"We need to have fixed breakpoint scales at which we can change the rendering. These should be \"round\" numbers so that we can replace without annoying rounding errors from fractional bases causing jitter. It makes sense to do it at the decade points, 1, 10, 100, etc. The current website also has breakpoints at intermediate values suggesting a need for greater definition. Scaling multiplies meaning that breakpoints need to be logarithmically distributed to be \"even\". For exmaple, if we were to have breaks at 100... and 500... this would be poor as there would be a jump of 5x followed by one of 2x between the scale points. The square root of ten is close to three, meaning choosing 100... and 300... gives jumps of 3x and 3 1/3x which is about 10% error, which is small, and provides round numbers for scales. Having more jump points would mean needing 2x jumps which interact badly with 10: 2x 2x 2x 2.625x. We can't have fewer intermediate jumps than the single one provided by 100..., 300..., so this is the best option.","title":"Context"},{"location":"arch/0005-breakpoints/#decision","text":"Break points at 100... and 300...","title":"Decision"},{"location":"arch/0005-breakpoints/#consequences","text":"We need to choose the best scales for style changes at one of these points.","title":"Consequences"},{"location":"arch/0006-bytecode/","text":"0006. Use of compiled bytecode language for styling Date: 2018-11 Status Provisional Consequence of None Context We need a way of styling tracks in the WebGL. As we are styling things down to WebGL triangles, not a DOM box model, we can't rely on CSS to do this and doesn't have quite the right paradigm, anyway. (We need something closer to PS/PDF/SVG primitives). We should choose a method which is: expressive; easy and quick to turn-aroud and edit to encourage experimentation; portable to different data-situations without code changes; simple to implement. (2) and (3) rule out direct hard-baking into the rust frontend. They suggest instead an asset, like CSS, which represents styling of data which the browser can grab and use to layer over the data. Languages like CSS (and DSSSL, etc, before it) tend to get conceptually \"hairy\" pretty quickly, developing various modes, by-ways, axes, units, etc, which interact in complex ways. The language of design is typically not strucutred in the rigid ontological frameworks which supports compact declarative specification. Pretty soon these languages end up supporting a surrogate, embedded programming language. These concerns speak against points (1) and (4) above. An alternative is to adopt an embeddable bytecode from the start. This need only implement basic arithmetic and boolean operations and, it turns out, can be implemented with parser, lexer, and full tests in <4kloc. This addresses (1,3,4) but pushes against (2): nobody wants to write bytecode. Instead, we ask that developers write in a source format which is transpiled to the bytecode format after each change. The bytecode gets sent over the wire. This source format can be a simple expression language or even a declarative \"config-file\" format, depending on developer experience, skills, requirements, etc, all compiled into the bytecode. Writing such a transpiler is a mature field with rich tools, which should be quick to achieve (as we don't need efficiency, our bytecode will be short). This addresses (2) without sacrificing (1,3,4). The embedded interpreter handles large volumes of data, so: needs to be efficient, but needs to play well as an embedded language, allowing other parts of the browser app to respond in a timely manner, etc. These two requirements tend to push against each other. Interpreted languages tend to be slow at instruction boundaries and embedded, interpreted languages even more so. Generally much of the time taken is in administrative tasks between instructions. A great deal of work has been done in the field to optimise this: sufficient to say that we don't want to go anywhere near there with a twelve foot barge-pole. Instead, we use a vector language. This means that tens of thousands of data-points can be manipulated within a single instruction, removing the number-of-objects factor from the overheads. In this situation the overheads again become insignificant. Our addition operation, for exmaple (to centre or displace a block, say), adds an array of numbers to another array of numbers. Thus every object can be shifted with a single instruction. (Languages like R and numpy show the value of this approach). The need for an embedded vector language means that no examined exisitng solutions (such as embedding Lua) could be found to fly. The additional requirment of a WASM target integrated with a rust application would have further complicated things. To aid debugging the \"bytecode\" should be human-readable at-a-push. In this case it should probably support a 1-to-1 to an assembler-like syntax. Fortunately implementing bytecode interpreters, despite sounding scary, requires nothing more than graduate computer science experience. Decision Implement an embedded bytecode interpreter parsed in the client from an assembler-like syntax. Consequences Longer term, we need to decide on the best \"source\" language for this. Whether it's a declarative, configuration-based source or a nicer rich input/config language, or some combination of these.","title":"0006 Use a bytecode"},{"location":"arch/0006-bytecode/#0006-use-of-compiled-bytecode-language-for-styling","text":"Date: 2018-11","title":"0006. Use of compiled bytecode language for styling"},{"location":"arch/0006-bytecode/#status","text":"Provisional","title":"Status"},{"location":"arch/0006-bytecode/#consequence-of","text":"None","title":"Consequence of"},{"location":"arch/0006-bytecode/#context","text":"We need a way of styling tracks in the WebGL. As we are styling things down to WebGL triangles, not a DOM box model, we can't rely on CSS to do this and doesn't have quite the right paradigm, anyway. (We need something closer to PS/PDF/SVG primitives). We should choose a method which is: expressive; easy and quick to turn-aroud and edit to encourage experimentation; portable to different data-situations without code changes; simple to implement. (2) and (3) rule out direct hard-baking into the rust frontend. They suggest instead an asset, like CSS, which represents styling of data which the browser can grab and use to layer over the data. Languages like CSS (and DSSSL, etc, before it) tend to get conceptually \"hairy\" pretty quickly, developing various modes, by-ways, axes, units, etc, which interact in complex ways. The language of design is typically not strucutred in the rigid ontological frameworks which supports compact declarative specification. Pretty soon these languages end up supporting a surrogate, embedded programming language. These concerns speak against points (1) and (4) above. An alternative is to adopt an embeddable bytecode from the start. This need only implement basic arithmetic and boolean operations and, it turns out, can be implemented with parser, lexer, and full tests in <4kloc. This addresses (1,3,4) but pushes against (2): nobody wants to write bytecode. Instead, we ask that developers write in a source format which is transpiled to the bytecode format after each change. The bytecode gets sent over the wire. This source format can be a simple expression language or even a declarative \"config-file\" format, depending on developer experience, skills, requirements, etc, all compiled into the bytecode. Writing such a transpiler is a mature field with rich tools, which should be quick to achieve (as we don't need efficiency, our bytecode will be short). This addresses (2) without sacrificing (1,3,4). The embedded interpreter handles large volumes of data, so: needs to be efficient, but needs to play well as an embedded language, allowing other parts of the browser app to respond in a timely manner, etc. These two requirements tend to push against each other. Interpreted languages tend to be slow at instruction boundaries and embedded, interpreted languages even more so. Generally much of the time taken is in administrative tasks between instructions. A great deal of work has been done in the field to optimise this: sufficient to say that we don't want to go anywhere near there with a twelve foot barge-pole. Instead, we use a vector language. This means that tens of thousands of data-points can be manipulated within a single instruction, removing the number-of-objects factor from the overheads. In this situation the overheads again become insignificant. Our addition operation, for exmaple (to centre or displace a block, say), adds an array of numbers to another array of numbers. Thus every object can be shifted with a single instruction. (Languages like R and numpy show the value of this approach). The need for an embedded vector language means that no examined exisitng solutions (such as embedding Lua) could be found to fly. The additional requirment of a WASM target integrated with a rust application would have further complicated things. To aid debugging the \"bytecode\" should be human-readable at-a-push. In this case it should probably support a 1-to-1 to an assembler-like syntax. Fortunately implementing bytecode interpreters, despite sounding scary, requires nothing more than graduate computer science experience.","title":"Context"},{"location":"arch/0006-bytecode/#decision","text":"Implement an embedded bytecode interpreter parsed in the client from an assembler-like syntax.","title":"Decision"},{"location":"arch/0006-bytecode/#consequences","text":"Longer term, we need to decide on the best \"source\" language for this. Whether it's a declarative, configuration-based source or a nicer rich input/config language, or some combination of these.","title":"Consequences"}]}